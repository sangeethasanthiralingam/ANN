{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 09. Mini GAN\n",
        "\n",
        "This notebook implements a minimal Generative Adversarial Network for synthetic data generation.\n",
        "\n",
        "## Experiment Overview\n",
        "- **Goal**: Generate synthetic data using Generative Adversarial Networks\n",
        "- **Model**: Generator + Discriminator with simple architectures\n",
        "- **Features**: Training dynamics, generated sample quality, loss curves\n",
        "- **Learning**: Understanding adversarial training and generative models\n",
        "\n",
        "## What You'll Learn\n",
        "- GAN architecture and training\n",
        "- Generator and discriminator design\n",
        "- Adversarial training dynamics\n",
        "- Generated sample quality assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add scripts directory to path\n",
        "sys.path.append('../scripts')\n",
        "from utils import get_device, set_seed\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Get device\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Generate real data (2D Gaussian)\n",
        "def generate_real_data(n_samples=1000):\n",
        "    \"\"\"Generate real data from 2D Gaussian.\"\"\"\n",
        "    return np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1]], n_samples)\n",
        "\n",
        "# Visualize real data\n",
        "real_data = generate_real_data(1000)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, c='blue')\n",
        "plt.title('Real Data Distribution')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.grid(True)\n",
        "plt.savefig('../results/plots/gan_real_data.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define Generator and Discriminator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim=2, output_dim=2, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(noise_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, noise):\n",
        "        return self.net(noise)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Create models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "print(\"Generator:\")\n",
        "print(generator)\n",
        "print(f\"Parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
        "\n",
        "print(\"\\nDiscriminator:\")\n",
        "print(discriminator)\n",
        "print(f\"Parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
        "\n",
        "# GAN Training function\n",
        "def train_gan(generator, discriminator, real_data, epochs=1000, lr=0.0002, batch_size=64):\n",
        "    \"\"\"Train GAN.\"\"\"\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    \n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Train Discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        \n",
        "        # Real data\n",
        "        real_batch = torch.FloatTensor(real_data[np.random.choice(len(real_data), batch_size)]).to(device)\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        real_output = discriminator(real_batch)\n",
        "        d_real_loss = F.binary_cross_entropy(real_output, real_labels)\n",
        "        \n",
        "        # Fake data\n",
        "        noise = torch.randn(batch_size, 2).to(device)\n",
        "        fake_batch = generator(noise)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        fake_output = discriminator(fake_batch.detach())\n",
        "        d_fake_loss = F.binary_cross_entropy(fake_output, fake_labels)\n",
        "        \n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        # Train Generator\n",
        "        g_optimizer.zero_grad()\n",
        "        noise = torch.randn(batch_size, 2).to(device)\n",
        "        fake_batch = generator(noise)\n",
        "        fake_output = discriminator(fake_batch)\n",
        "        g_loss = F.binary_cross_entropy(fake_output, real_labels)\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        g_losses.append(g_loss.item())\n",
        "        d_losses.append(d_loss.item())\n",
        "        \n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, G Loss: {g_loss.item():.4f}, D Loss: {d_loss.item():.4f}')\n",
        "    \n",
        "    return g_losses, d_losses\n",
        "\n",
        "# Train GAN\n",
        "print(\"Training GAN...\")\n",
        "g_losses, d_losses = train_gan(generator, discriminator, real_data, epochs=1000)\n",
        "\n",
        "# Plot training losses\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(g_losses, label='Generator Loss')\n",
        "plt.plot(d_losses, label='Discriminator Loss')\n",
        "plt.title('GAN Training Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(g_losses, label='Generator Loss')\n",
        "plt.plot(d_losses, label='Discriminator Loss')\n",
        "plt.title('GAN Training Losses (Log Scale)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (log)')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/plots/gan_training.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate and visualize fake data\n",
        "def generate_fake_data(generator, n_samples=1000):\n",
        "    \"\"\"Generate fake data using trained generator.\"\"\"\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(n_samples, 2).to(device)\n",
        "        fake_data = generator(noise).cpu().numpy()\n",
        "    return fake_data\n",
        "\n",
        "# Generate fake data\n",
        "fake_data = generate_fake_data(generator, 1000)\n",
        "\n",
        "# Visualize real vs fake data\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, c='blue', label='Real')\n",
        "plt.title('Real Data')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(fake_data[:, 0], fake_data[:, 1], alpha=0.6, c='red', label='Fake')\n",
        "plt.title('Generated Data')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, c='blue', label='Real')\n",
        "plt.scatter(fake_data[:, 0], fake_data[:, 1], alpha=0.6, c='red', label='Fake')\n",
        "plt.title('Real vs Generated')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/plots/gan_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Save models\n",
        "torch.save(generator.state_dict(), '../results/logs/generator.pth')\n",
        "torch.save(discriminator.state_dict(), '../results/logs/discriminator.pth')\n",
        "\n",
        "print(\"GAN training completed and models saved!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
