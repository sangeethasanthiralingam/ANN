{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06. Mini CNN\n",
        "\n",
        "This notebook implements a minimal Convolutional Neural Network for image classification.\n",
        "\n",
        "## Experiment Overview\n",
        "- **Goal**: Image classification using convolutional layers\n",
        "- **Model**: Simple CNN (Conv2D → MaxPool → FC)\n",
        "- **Features**: CIFAR-10 classification, feature map visualization\n",
        "- **Learning**: Understanding convolutional neural networks\n",
        "\n",
        "## What You'll Learn\n",
        "- Convolutional layers and operations\n",
        "- Pooling and feature extraction\n",
        "- CNN architecture design\n",
        "- Feature map visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add scripts directory to path\n",
        "sys.path.append('../scripts')\n",
        "from utils import load_cifar10_data, plot_training_history, plot_confusion_matrix, get_device, set_seed\n",
        "from train import train_model\n",
        "from evaluate import evaluate_model\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Get device\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "print(\"Loading CIFAR-10 dataset...\")\n",
        "train_loader, val_loader, test_loader = load_cifar10_data(batch_size=64, test_split=0.2)\n",
        "\n",
        "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
        "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Visualize some training samples\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "for i in range(10):\n",
        "    row, col = i // 5, i % 5\n",
        "    # Get a batch and show first sample\n",
        "    data, target = next(iter(train_loader))\n",
        "    # CIFAR-10 images need to be denormalized for display\n",
        "    img = data[0].permute(1, 2, 0)\n",
        "    img = img * 0.5 + 0.5  # Denormalize\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    axes[row, col].imshow(img)\n",
        "    axes[row, col].set_title(f'{class_names[target[0].item()]}')\n",
        "    axes[row, col].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Mini CNN model\n",
        "class MiniCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MiniCNN, self).__init__()\n",
        "        \n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)  # 32x32 -> 16x16 -> 8x8 -> 4x4 after 3 pools\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        \n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # First conv block\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # Second conv block\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # Third conv block\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Create model instance\n",
        "model = MiniCNN().to(device)\n",
        "\n",
        "# Print model summary\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Model size: {sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Test forward pass\n",
        "with torch.no_grad():\n",
        "    dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "    output = model(dummy_input)\n",
        "    print(f\"Output shape: {output.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting CNN training...\")\n",
        "trainer = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    task_type='classification',\n",
        "    epochs=20,\n",
        "    lr=0.001,\n",
        "    device=device,\n",
        "    save_dir='../results/logs/mini_cnn'\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "trainer.plot_training_history(save_path='../results/plots/mini_cnn_training.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on test set\n",
        "print(\"Evaluating on test set...\")\n",
        "results = evaluate_model(\n",
        "    model=model,\n",
        "    data_loader=test_loader,\n",
        "    task_type='classification',\n",
        "    device=device,\n",
        "    save_dir='../results/plots/mini_cnn'\n",
        ")\n",
        "\n",
        "# Show some predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Get a batch of test data\n",
        "    data, target = next(iter(test_loader))\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    pred = output.argmax(dim=1)\n",
        "    \n",
        "    # Visualize predictions\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "    for i in range(10):\n",
        "        row, col = i // 5, i % 5\n",
        "        # Denormalize image for display\n",
        "        img = data[i].cpu().permute(1, 2, 0)\n",
        "        img = img * 0.5 + 0.5\n",
        "        img = torch.clamp(img, 0, 1)\n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].set_title(f'True: {class_names[target[i].item()]}\\\\nPred: {class_names[pred[i].item()]}')\n",
        "        axes[row, col].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(f\"\\\\nFinal Test Accuracy: {results['accuracy']:.4f}\")\n",
        "print(f\"Final Test F1-Score: {results['f1_score']:.4f}\")\n",
        "\n",
        "# Feature map visualization\n",
        "def visualize_feature_maps(model, image, layer_name, device):\n",
        "    \"\"\"Visualize feature maps from a specific layer.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Hook to capture feature maps\n",
        "    feature_maps = {}\n",
        "    def hook_fn(module, input, output):\n",
        "        feature_maps[layer_name] = output.detach()\n",
        "    \n",
        "    # Register hook\n",
        "    if layer_name == 'conv1':\n",
        "        hook = model.conv1.register_forward_hook(hook_fn)\n",
        "    elif layer_name == 'conv2':\n",
        "        hook = model.conv2.register_forward_hook(hook_fn)\n",
        "    elif layer_name == 'conv3':\n",
        "        hook = model.conv3.register_forward_hook(hook_fn)\n",
        "    \n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        _ = model(image.unsqueeze(0).to(device))\n",
        "    \n",
        "    # Remove hook\n",
        "    hook.remove()\n",
        "    \n",
        "    # Get feature maps\n",
        "    fmaps = feature_maps[layer_name][0]  # First sample in batch\n",
        "    \n",
        "    # Visualize first 16 feature maps\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "    for i in range(16):\n",
        "        row, col = i // 4, i % 4\n",
        "        if i < fmaps.shape[0]:\n",
        "            axes[row, col].imshow(fmaps[i].cpu().numpy(), cmap='viridis')\n",
        "            axes[row, col].set_title(f'Channel {i}')\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Feature Maps from {layer_name}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize feature maps for a sample image\n",
        "sample_image, _ = next(iter(test_loader))\n",
        "sample_image = sample_image[0]  # Take first image\n",
        "\n",
        "print(\"Visualizing feature maps...\")\n",
        "for layer in ['conv1', 'conv2', 'conv3']:\n",
        "    visualize_feature_maps(model, sample_image, layer, device)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
