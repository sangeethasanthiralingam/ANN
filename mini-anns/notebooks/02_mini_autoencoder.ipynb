{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02. Mini Autoencoder\n",
        "\n",
        "This notebook implements a minimal autoencoder to learn compressed representations of MNIST images.\n",
        "\n",
        "## Experiment Overview\n",
        "- **Goal**: Learn compressed representations of MNIST images using an autoencoder\n",
        "- **Model**: Encoder-decoder architecture (784 → 32 → 784)\n",
        "- **Features**: Reconstruction visualization, latent space exploration\n",
        "- **Learning**: Understanding unsupervised learning and dimensionality reduction\n",
        "\n",
        "## What You'll Learn\n",
        "- Building encoder-decoder architectures\n",
        "- Unsupervised learning with autoencoders\n",
        "- Latent space visualization\n",
        "- Reconstruction quality assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Add scripts directory to path\n",
        "sys.path.append('../scripts')\n",
        "from utils import load_mnist_data, get_device, set_seed\n",
        "from train import train_model\n",
        "from evaluate import ModelEvaluator\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Get device\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Mini Autoencoder model\n",
        "class MiniAutoencoder(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=32):\n",
        "        super(MiniAutoencoder, self).__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, hidden_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_size),\n",
        "            nn.Sigmoid()  # Output between 0 and 1\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Flatten input\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Encode\n",
        "        encoded = self.encoder(x)\n",
        "        \n",
        "        # Decode\n",
        "        decoded = self.decoder(encoded)\n",
        "        \n",
        "        return decoded, encoded\n",
        "    \n",
        "    def encode(self, x):\n",
        "        \"\"\"Encode input to latent space.\"\"\"\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.encoder(x)\n",
        "    \n",
        "    def decode(self, z):\n",
        "        \"\"\"Decode from latent space.\"\"\"\n",
        "        return self.decoder(z)\n",
        "\n",
        "# Create model instance\n",
        "model = MiniAutoencoder().to(device)\n",
        "\n",
        "# Print model summary\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Model size: {sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "print(\"Loading MNIST dataset...\")\n",
        "train_loader, val_loader, test_loader = load_mnist_data(batch_size=64, test_split=0.2)\n",
        "\n",
        "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
        "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
        "\n",
        "# Visualize some training samples\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "for i in range(10):\n",
        "    row, col = i // 5, i % 5\n",
        "    # Get a batch and show first sample\n",
        "    data, target = next(iter(train_loader))\n",
        "    axes[row, col].imshow(data[0].squeeze(), cmap='gray')\n",
        "    axes[row, col].set_title(f'Label: {target[0].item()}')\n",
        "    axes[row, col].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom training function for autoencoder\n",
        "def train_autoencoder(model, train_loader, val_loader, epochs=20, lr=0.001, device='cpu'):\n",
        "    \"\"\"Train autoencoder with reconstruction loss.\"\"\"\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            reconstructed, _ = model(data)\n",
        "            loss = criterion(reconstructed, data.view(data.size(0), -1))\n",
        "            \n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, _ in val_loader:\n",
        "                data = data.to(device)\n",
        "                reconstructed, _ = model(data)\n",
        "                loss = criterion(reconstructed, data.view(data.size(0), -1))\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss /= len(val_loader)\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
        "    \n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Train the autoencoder\n",
        "print(\"Starting autoencoder training...\")\n",
        "train_losses, val_losses = train_autoencoder(model, train_loader, val_loader, epochs=20, device=device)\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Autoencoder Training History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Reconstruction Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Training History (Log Scale)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Reconstruction Loss (log)')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/plots/autoencoder_training.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize reconstructions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Get a batch of test data\n",
        "    data, target = next(iter(test_loader))\n",
        "    data = data.to(device)\n",
        "    \n",
        "    # Get reconstructions\n",
        "    reconstructed, encoded = model(data)\n",
        "    \n",
        "    # Convert to numpy for visualization\n",
        "    original = data.cpu().numpy()\n",
        "    reconstructed = reconstructed.cpu().numpy()\n",
        "    \n",
        "    # Show original vs reconstructed\n",
        "    fig, axes = plt.subplots(4, 10, figsize=(15, 6))\n",
        "    for i in range(10):\n",
        "        # Original images\n",
        "        axes[0, i].imshow(original[i].squeeze(), cmap='gray')\n",
        "        axes[0, i].set_title(f'Original {target[i].item()}')\n",
        "        axes[0, i].axis('off')\n",
        "        \n",
        "        # Reconstructed images\n",
        "        axes[1, i].imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
        "        axes[1, i].set_title('Reconstructed')\n",
        "        axes[1, i].axis('off')\n",
        "        \n",
        "        # Difference\n",
        "        diff = np.abs(original[i].squeeze() - reconstructed[i].reshape(28, 28))\n",
        "        axes[2, i].imshow(diff, cmap='hot')\n",
        "        axes[2, i].set_title('Difference')\n",
        "        axes[2, i].axis('off')\n",
        "        \n",
        "        # Latent space (first 2 dimensions)\n",
        "        axes[3, i].scatter(encoded[i, 0].cpu(), encoded[i, 1].cpu(), c=target[i].item(), cmap='tab10')\n",
        "        axes[3, i].set_title('Latent (2D)')\n",
        "        axes[3, i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../results/plots/autoencoder_reconstructions.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize latent space using t-SNE\n",
        "print(\"Computing t-SNE visualization of latent space...\")\n",
        "\n",
        "# Collect all encoded representations and labels\n",
        "all_encoded = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        _, encoded = model(data)\n",
        "        all_encoded.append(encoded.cpu().numpy())\n",
        "        all_labels.append(target.numpy())\n",
        "\n",
        "all_encoded = np.vstack(all_encoded)\n",
        "all_labels = np.hstack(all_labels)\n",
        "\n",
        "# Use t-SNE to reduce to 2D\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "encoded_2d = tsne.fit_transform(all_encoded)\n",
        "\n",
        "# Plot latent space\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "scatter = plt.scatter(encoded_2d[:, 0], encoded_2d[:, 1], c=all_labels, cmap='tab10', alpha=0.6)\n",
        "plt.colorbar(scatter)\n",
        "plt.title('Latent Space (t-SNE)')\n",
        "plt.xlabel('t-SNE 1')\n",
        "plt.ylabel('t-SNE 2')\n",
        "\n",
        "# Plot latent space colored by digit\n",
        "plt.subplot(1, 2, 2)\n",
        "for digit in range(10):\n",
        "    mask = all_labels == digit\n",
        "    plt.scatter(encoded_2d[mask, 0], encoded_2d[mask, 1], \n",
        "               label=f'Digit {digit}', alpha=0.6, s=20)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.title('Latent Space by Digit')\n",
        "plt.xlabel('t-SNE 1')\n",
        "plt.ylabel('t-SNE 2')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/plots/autoencoder_latent_space.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Calculate reconstruction error\n",
        "mse = np.mean((all_encoded - all_encoded) ** 2)  # This should be 0, let's calculate actual reconstruction error\n",
        "print(f\"Latent space dimension: {all_encoded.shape[1]}\")\n",
        "print(f\"Compression ratio: {784 / all_encoded.shape[1]:.1f}x\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
