{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. Energy Efficient ANN\n",
        "\n",
        "This notebook explores energy-efficient neural network designs.\n",
        "\n",
        "## Experiment Overview\n",
        "- **Goal**: Explore energy-efficient neural network designs\n",
        "- **Model**: Quantized and pruned networks\n",
        "- **Features**: Energy consumption estimation, accuracy-efficiency trade-offs\n",
        "- **Learning**: Understanding model efficiency and optimization\n",
        "\n",
        "## What You'll Learn\n",
        "- Model quantization techniques\n",
        "- Energy consumption estimation\n",
        "- Accuracy vs. efficiency trade-offs\n",
        "- Efficient neural network design\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Add scripts directory to path\n",
        "sys.path.append('../scripts')\n",
        "from utils import load_mnist_data, get_device, set_seed\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Get device\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")-\n",
        "\n",
        "# Load MNIST dataset\n",
        "print(\"Loading MNIST dataset...\")\n",
        "train_loader, val_loader, test_loader = load_mnist_data(batch_size=64, test_split=0.2)\n",
        "\n",
        "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
        "print(f\"Test samples: {len(test_loader.dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define energy-efficient models\n",
        "class EnergyEfficientMLP(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=64, num_classes=10):\n",
        "        super(EnergyEfficientMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class QuantizedMLP(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=64, num_classes=10):\n",
        "        super(QuantizedMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create models\n",
        "efficient_model = EnergyEfficientMLP().to(device)\n",
        "quantized_model = QuantizedMLP().to(device)\n",
        "\n",
        "print(\"Energy Efficient Model:\")\n",
        "print(efficient_model)\n",
        "print(f\"Parameters: {sum(p.numel() for p in efficient_model.parameters()):,}\")\n",
        "\n",
        "print(\"\\nQuantized Model:\")\n",
        "print(quantized_model)\n",
        "print(f\"Parameters: {sum(p.numel() for p in quantized_model.parameters()):,}\")\n",
        "\n",
        "# Training function with timing\n",
        "def train_model_with_timing(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
        "    \"\"\"Train model and measure time.\"\"\"\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    training_times = []\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "        epoch_time = time.time() - epoch_start\n",
        "        training_times.append(epoch_time)\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss /= len(val_loader)\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Time: {epoch_time:.2f}s')\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    return train_losses, val_losses, training_times, total_time\n",
        "\n",
        "# Train both models\n",
        "print(\"Training Energy Efficient Model...\")\n",
        "eff_train_losses, eff_val_losses, eff_times, eff_total_time = train_model_with_timing(\n",
        "    efficient_model, train_loader, val_loader, epochs=10\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Quantized Model...\")\n",
        "quant_train_losses, quant_val_losses, quant_times, quant_total_time = train_model_with_timing(\n",
        "    quantized_model, train_loader, val_loader, epochs=10\n",
        ")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(eff_train_losses, label='Efficient Train')\n",
        "plt.plot(eff_val_losses, label='Efficient Val')\n",
        "plt.plot(quant_train_losses, label='Quantized Train')\n",
        "plt.plot(quant_val_losses, label='Quantized Val')\n",
        "plt.title('Training Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(eff_times, label='Efficient')\n",
        "plt.plot(quant_times, label='Quantized')\n",
        "plt.title('Training Time per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Time (s)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "models = ['Efficient', 'Quantized']\n",
        "total_times = [eff_total_time, quant_total_time]\n",
        "plt.bar(models, total_times)\n",
        "plt.title('Total Training Time')\n",
        "plt.ylabel('Time (s)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "params = [sum(p.numel() for p in efficient_model.parameters()), \n",
        "          sum(p.numel() for p in quantized_model.parameters())]\n",
        "plt.bar(models, params)\n",
        "plt.title('Model Parameters')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "model_sizes = [p * 4 / 1024 / 1024 for p in params]  # MB\n",
        "plt.bar(models, model_sizes)\n",
        "plt.title('Model Size')\n",
        "plt.ylabel('Size (MB)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "efficiency = [acc / time for acc, time in zip([max(eff_val_losses), max(quant_val_losses)], total_times)]\n",
        "plt.bar(models, efficiency)\n",
        "plt.title('Training Efficiency (Loss/Time)')\n",
        "plt.ylabel('Efficiency')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/plots/energy_efficiency.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nEnergy Efficiency Summary:\")\n",
        "print(f\"Efficient Model - Total Time: {eff_total_time:.2f}s, Parameters: {params[0]:,}\")\n",
        "print(f\"Quantized Model - Total Time: {quant_total_time:.2f}s, Parameters: {params[1]:,}\")\n",
        "print(f\"Time Reduction: {((eff_total_time - quant_total_time) / eff_total_time * 100):.1f}%\")\n",
        "print(f\"Parameter Reduction: {((params[0] - params[1]) / params[0] * 100):.1f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
